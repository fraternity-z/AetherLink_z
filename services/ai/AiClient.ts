import { streamText, experimental_generateImage as generateImage, type ModelMessage } from 'ai';
import { createOpenAI } from '@ai-sdk/openai';
import { createOpenAICompatible } from '@ai-sdk/openai-compatible';
import { createAnthropic } from '@ai-sdk/anthropic';
import { createGoogleGenerativeAI } from '@ai-sdk/google';
import { ProvidersRepository, type ProviderId } from '@/storage/repositories/providers';
import { ImageGenerationError, ImageModelResolutionError } from './errors';
import { isDedicatedImageGenerationModel } from './ModelDiscovery';
import { logger } from '@/utils/logger';
import { mcpClient } from '@/services/mcp/McpClient';
import { McpServersRepository } from '@/storage/repositories/mcp';
import type { MCPTool, MCPToolResult } from '@/types/mcp';

export type Provider = 'openai' | 'anthropic' | 'google' | 'gemini' | 'deepseek' | 'volc' | 'zhipu';

export interface StreamOptions {
  provider: Provider;
  model: string;
  messages: ModelMessage[];
  abortSignal?: AbortSignal;
  temperature?: number;
  maxTokens?: number;
  onToken?: (delta: string) => void;
  onDone?: () => void;
  onError?: (e: unknown) => void;

  // æ€è€ƒé“¾å›è°ƒ (ç”¨äºæ”¯æŒæ¨ç†æ¨¡å‹å¦‚ OpenAI o1/o3, DeepSeek R1 ç­‰)
  onThinkingToken?: (delta: string) => void;
  onThinkingStart?: () => void;
  onThinkingEnd?: () => void;

  // MCP å·¥å…·é›†æˆ (Model Context Protocol)
  enableMcpTools?: boolean; // æ˜¯å¦å¯ç”¨ MCP å·¥å…·
  onToolCall?: (toolName: string, args: any) => void; // å·¥å…·è°ƒç”¨å¼€å§‹å›è°ƒ
  onToolResult?: (toolName: string, result: any) => void; // å·¥å…·æ‰§è¡Œå®Œæˆå›è°ƒ
}

async function getApiKey(provider: Provider): Promise<string> {
  // ç»Ÿä¸€ä½¿ç”¨ ProvidersRepository è·å–æ‰€æœ‰æä¾›å•†çš„ API Key
  const normalizedProvider = provider === 'gemini' ? 'google' : provider;
  return (await ProvidersRepository.getApiKey(normalizedProvider as ProviderId)) ?? '';
}

/**
 * æ£€æµ‹æ¨¡å‹æ˜¯å¦æ”¯æŒæ€è€ƒé“¾(Reasoning)åŠŸèƒ½
 */
function supportsReasoning(provider: Provider, model: string): boolean {
  const modelLower = model.toLowerCase();

  // OpenAI o1/o3/o4 ç³»åˆ—
  if (provider === 'openai' && /^o[134](-preview|-mini)?$/i.test(model)) {
    return true;
  }

  // DeepSeek R1 ç³»åˆ— (æ”¯æŒé€šè¿‡ openai å…¼å®¹æ¥å£æˆ– deepseek ç›´æ¥è°ƒç”¨)
  // åŒ¹é…: deepseek-r1, deepseek-reasoner, r1, ç­‰
  if (/deepseek.*r1|^r1$|reasoner/i.test(modelLower)) {
    return true;
  }

  // Anthropic Claude 3.7+
  if (provider === 'anthropic' && /claude-3\.[789]|claude-[4-9]/i.test(model)) {
    return true;
  }

  // Google Gemini Thinking æ¨¡å‹
  if ((provider === 'google' || provider === 'gemini') && /thinking/i.test(model)) {
    return true;
  }

  return false;
}

/**
 * è·å–æ¨ç†æ¨¡å‹çš„ providerOptions é…ç½®
 */
function getProviderOptions(provider: Provider, model: string): any {
  // OpenAI o1/o3 ç³»åˆ— - éœ€è¦ reasoningSummary é…ç½®
  if (provider === 'openai' && /^o[134]/i.test(model)) {
    return {
      providerOptions: {
        openai: {
          reasoningSummary: 'detailed',
        },
      },
    };
  }

  // Anthropic Claude 3.7+ - éœ€è¦å¯ç”¨ thinking
  if (provider === 'anthropic' && /claude-3\.[789]|claude-[4-9]/i.test(model)) {
    return {
      providerOptions: {
        anthropic: {
          thinking: {
            type: 'enabled',
            budgetTokens: 12000,
          },
        },
      },
    };
  }

  // DeepSeek R1 å’Œ Google Thinking å¯èƒ½ä¸éœ€è¦ç‰¹æ®Šé…ç½®
  return {};
}

export async function streamCompletion(opts: StreamOptions) {
  // ç»Ÿä¸€è§£æä¸è§„èŒƒåŒ– provider/modelï¼Œé¿å…å…¼å®¹ç«¯ç‚¹è·¯ç”±è¯¯åˆ¤
  let provider: Provider = opts.provider;
  const model = opts.model;

  // é’ˆå¯¹ deepseek-r1/"reasoner" ç­‰æ¨¡å‹ï¼š
  // è‹¥ç”¨æˆ·åœ¨ UI ä¸­é€‰æ‹©äº† provider=openai ä½† model å±äº deepseek ç³»åˆ—ï¼Œ
  // ä¸” openai çš„ baseURL æœªæŒ‡å‘å…¼å®¹ç«¯ç‚¹ï¼Œåˆ™ä¼˜å…ˆåˆ‡æ¢åˆ° deepseek providerï¼Œ
  // ä»¥å¼ºåˆ¶èµ° openai-compatible æµç¨‹ï¼Œé¿å…é¦–æ¡æ¶ˆæ¯è¯¯è¿ openai å®˜æ–¹ç«¯ç‚¹æŠ¥é”™ã€‚
  // æ ‡è®°æ˜¯å¦å·²å®Œæˆï¼ˆç”¨äºå¿½ç•¥ "finish" ä¹‹åçš„æ™šåˆ°é”™è¯¯ï¼‰
  let didFinish = false;

  try {
    const openaiCfg = provider === 'openai' ? await ProvidersRepository.getConfig('openai' as ProviderId) : null;
    const openaiBase = provider === 'openai' ? String(openaiCfg?.baseURL || '').replace(/\/$/, '') : '';
    const isOpenAIOfficial = provider === 'openai' && (!openaiBase || /^https?:\/\/api\.openai\.com\/?v1?$/i.test(openaiBase));

    const isOpenAIOfficialModel = (m: string) => {
      const s = m.toLowerCase();
      return (
        /^gpt-/.test(s) ||
        /^o[0-9]/.test(s) ||
        s.includes('dall-e') ||
        s.startsWith('gpt-image-') ||
        s.startsWith('text-embedding-') ||
        s.startsWith('whisper-')
      );
    };

    async function pickCompatibleProvider(): Promise<Provider | null> {
      const candidates: Provider[] = ['deepseek', 'volc', 'zhipu'];
      for (const id of candidates) {
        const key = await ProvidersRepository.getApiKey(id as ProviderId);
        const cfg = await ProvidersRepository.getConfig(id as ProviderId);
        if (key || cfg?.baseURL) return id;
      }
      return null;
    }

    if (isOpenAIOfficial && !isOpenAIOfficialModel(model)) {
      const compat = await pickCompatibleProvider();
      if (compat) {
        provider = compat;
        const cfg = await ProvidersRepository.getConfig(compat as ProviderId);
        logger.info('[AiClient] è§„èŒƒåŒ–è·¯ç”±: openai å®˜æ–¹ç«¯ç‚¹ + éå®˜æ–¹æ¨¡å‹ -> åˆ‡æ¢åˆ°å…¼å®¹æä¾›å•†', {
          model,
          compatProvider: provider,
          baseURL: cfg?.baseURL || '(default)'
        });
      } else {
        logger.warn('[AiClient] æ£€æµ‹åˆ° openai å®˜æ–¹ç«¯ç‚¹ + éå®˜æ–¹æ¨¡å‹ï¼Œä½†æœªå‘ç°å·²é…ç½®çš„å…¼å®¹æä¾›å•†', { model });
      }
    }
  } catch (e) {
    // ä»…è®°å½•è°ƒè¯•ï¼Œä¸é˜»æ–­æµç¨‹
    logger.debug('[AiClient] provider/model è§„èŒƒåŒ–æ£€æŸ¥å¼‚å¸¸ï¼ˆå¿½ç•¥ç»§ç»­ï¼‰', e);
  }

  // å…¼å®¹åˆ«å
  if (provider === 'gemini') provider = 'google';

  const apiKey = await getApiKey(provider);
  if (!apiKey) throw new Error('Missing API key for ' + provider);

  // resolve baseURL for openai-compatible vendors
  let baseURL: string | undefined;
  if (provider === 'openai' || provider === 'deepseek' || provider === 'volc' || provider === 'zhipu') {
    const cfg = await ProvidersRepository.getConfig(provider as ProviderId);
    baseURL = cfg.baseURL || undefined;
  }

  // resolve baseURL for anthropic
  let anthropicBaseURL: string | undefined;
  if (provider === 'anthropic') {
    const cfg = await ProvidersRepository.getConfig(provider as ProviderId);
    anthropicBaseURL = cfg.baseURL || undefined;
  }

  // choose provider factory with compatibility for OpenAI-compatible gateways
  const useOpenAICompatible = (
    provider === 'deepseek' || provider === 'volc' || provider === 'zhipu' ||
    (provider === 'openai' && !!baseURL && !/^https?:\/\/api\.openai\.com\/?v1\/?$/i.test(String(baseURL).replace(/\/$/, '')))
  );

  const factory =
    provider === 'anthropic'
      ? () => createAnthropic({ apiKey, baseURL: anthropicBaseURL })
      : provider === 'google'
      ? () => createGoogleGenerativeAI({ apiKey })
      : useOpenAICompatible
      ? () => createOpenAICompatible({
        apiKey, baseURL: baseURL ?? 'https://api.openai.com/v1',
        name: ''
      })
      : () => createOpenAI({ apiKey, baseURL });

  // æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æŒæ€è€ƒé“¾
  const hasReasoningSupport = supportsReasoning(provider, model);

  // MCP å·¥å…·é›†æˆï¼šå¦‚æœå¯ç”¨ï¼ŒåŠ è½½æ‰€æœ‰æ¿€æ´»çš„ MCP å·¥å…·
  let mcpTools: Record<string, any> | undefined;
  if (opts.enableMcpTools) {
    try {
      const { ToolConverter } = await import('@/services/mcp/ToolConverter');
      mcpTools = await ToolConverter.getAllActiveTools();
      logger.info('[AiClient] MCP å·¥å…·å·²åŠ è½½', {
        toolCount: Object.keys(mcpTools).length,
      });
    } catch (error: any) {
      // ç»Ÿä¸€æ—¥å¿—å½¢æ€ï¼šerror æ”¾ç¬¬äºŒå‚ï¼Œé™„åŠ å­—æ®µæ”¾ç¬¬ä¸‰å‚
      logger.error('[AiClient] åŠ è½½ MCP å·¥å…·å¤±è´¥', error, { message: error?.message });
      // å³ä½¿å·¥å…·åŠ è½½å¤±è´¥ï¼Œä»ç„¶ç»§ç»­èŠå¤©æµç¨‹
      mcpTools = undefined;
    }
  }

  // é‡‡ç”¨â€œæ–¹æ¡ˆAâ€ï¼šä¸å°† MCP å·¥å…·æ³¨å…¥ AI SDK çš„ tools æœºåˆ¶ï¼Œé¿å…ä¸»æµåœ¨å·¥å…·é˜¶æ®µè¢«é˜»å¡ã€‚
  // å·¥å…·è°ƒç”¨é‡‡ç”¨è§£è€¦çš„äºŒæ®µå¼ï¼š
  // 1) ç¬¬ä¸€æ®µï¼šçº¯æµå¼æ–‡æœ¬è¾“å‡ºï¼ŒæœŸé—´è§£æ <tool_use> æŒ‡ä»¤ï¼›
  // 2) æµç»“æŸåï¼šå¹¶å‘æ‰§è¡Œå·¥å…·ï¼›
  // 3) æ„é€ å¸¦å·¥å…·ç»“æœçš„æ–°æ¶ˆæ¯ï¼Œé€’å½’å¼€å¯ç¬¬äºŒæ®µæ¨¡å‹æµã€‚

  // å·¥å…·ä½¿ç”¨è§£æçš„èšåˆçŠ¶æ€
  const toolUses: Array<{ name: string; args: any }> = [];
  let toolDetected = false; // ä¸€æ—¦å‘ç°å®Œæ•´çš„å·¥å…·å—ï¼Œåç»­ä¸å†å‘ UI è¾“å‡ºæ–‡æœ¬ï¼Œé˜²æ­¢å¹»è§‰
  const toolParsingEnabled = opts.enableMcpTools === true;

  const extractToolUses = (aggregate: string) => {
    // è§£æ <tool_use> ... <name>...</name> ... <arguments>...</arguments> ... </tool_use>
    const re = /<tool_use>[\s\S]*?<name>[\s\S]*?<\/name>[\s\S]*?<arguments>[\s\S]*?<\/arguments>[\s\S]*?<\/tool_use>/g;
    const results: Array<{ name: string; args: any }> = [];
    let m: RegExpExecArray | null;
    while ((m = re.exec(aggregate)) !== null) {
      const block = m[0];
      const nameMatch = block.match(/<name>([\s\S]*?)<\/name>/);
      const argsMatch = block.match(/<arguments>([\s\S]*?)<\/arguments>/);
      if (!nameMatch || !argsMatch) continue;
      const rawName = (nameMatch[1] || '').trim();
      const rawArgs = (argsMatch[1] || '').trim();
      let parsedArgs: any = rawArgs;
      try {
        parsedArgs = JSON.parse(rawArgs);
      } catch {}
      results.push({ name: rawName, args: parsedArgs });
    }
    return results;
  };

  // å¦‚æœå¯ç”¨ MCP å·¥å…·ï¼Œå‘æ¨¡å‹æ³¨å…¥ä¸€æ®µç³»ç»Ÿæç¤ºï¼Œå‘ŠçŸ¥å¯ç”¨å·¥å…·ä»¥åŠä½¿ç”¨åè®®
  let initialMessages = opts.messages as ModelMessage[];
  if (opts.enableMcpTools) {
    try {
      const activeServers = await McpServersRepository.getActiveServers();
      const toolNames: string[] = [];
      const toolHints: string[] = [];
      for (const srv of activeServers) {
        try {
          const tools = await mcpClient.listTools(srv.id);
          for (const t of tools) {
            toolNames.push(t.name);
            const required = Array.isArray(t.inputSchema?.required) ? t.inputSchema.required : [];
            const props = t.inputSchema?.properties ? Object.keys(t.inputSchema.properties) : [];
            const keysPreview = (required as string[]).length > 0 ? `required: ${required.join(', ')}` : props.length > 0 ? `keys: ${props.slice(0,6).join(', ')}${props.length>6?'â€¦':''}` : '';
            toolHints.push(`- ${t.name}${keysPreview ? ` (${keysPreview})` : ''}`);
          }
        } catch (e) {
          logger.warn('[AiClient] é¢„åŠ è½½å·¥å…·åˆ—è¡¨å¤±è´¥ï¼Œè·³è¿‡è¯¥æœåŠ¡å™¨', { serverId: srv.id, error: (e as any)?.message });
        }
      }

      if (toolNames.length > 0) {
        const sysText = [
          'You can use external tools via Model Context Protocol (MCP).',
          'When a tool would help, emit exactly this tag and nothing else:',
          '<tool_use>\n<name>{tool_name}</name>\n<arguments>{valid JSON arguments}</arguments>\n</tool_use>',
          'Rules:',
          '- Use double quotes for all JSON keys/strings; no trailing commas;',
          '- Do NOT wrap with code fences; output only the tag above;',
          '- Stop generating immediately after </tool_use>.',
          'Available tools:',
          ...toolHints,
        ].join('\n');
        initialMessages = [{ role: 'system', content: sysText }, ...initialMessages];
      }
    } catch (e) {
      logger.warn('[AiClient] æ„å»º MCP å·¥å…·ç³»ç»Ÿæç¤ºå¤±è´¥', { error: (e as any)?.message });
    }
  }

  // é€’å½’å‡½æ•°ï¼šæ‰§è¡Œä¸€æ®µæµ + è§£æå·¥å…· + äºŒæ®µå¼é€’å½’ï¼ˆæœ€å¤š 3 å±‚ï¼‰
  const runOnePass = async (
    messages: any[],
    depth: number
  ): Promise<void> => {
    const result = streamText({
      model: factory()(model),
      messages,
      abortSignal: opts.abortSignal,
      temperature: opts.temperature,
      maxOutputTokens: opts.maxTokens,
      ...(hasReasoningSupport ? getProviderOptions(provider, model) : {}),
    });

    // æ¯æ®µæµçš„æœ¬åœ°èšåˆæ–‡æœ¬ï¼ˆä»…ç”¨äºæ£€æµ‹å·¥å…·å—ï¼‰ï¼Œä¸ºé™ä½å†…å­˜é£é™©ï¼Œé™åˆ¶åˆ° 50kã€‚
    let aggregateText = '';
    const appendAggregate = (d: string) => {
      aggregateText += d;
      if (aggregateText.length > 50000) {
        aggregateText = aggregateText.slice(-30000);
      }
    };

    try {
      if (hasReasoningSupport && (opts.onThinkingToken || opts.onThinkingStart || opts.onThinkingEnd)) {
        let isThinking = false;
        didFinish = false;

        for await (const part of result.fullStream) {
          logger.debug('[AiClient] ğŸ” fullStream part.type:', part.type);
          if (part.type === 'reasoning-start') {
            isThinking = true;
            opts.onThinkingStart?.();
          } else if (part.type === 'reasoning-delta') {
            opts.onThinkingToken?.(part.text);
          } else if (part.type === 'reasoning-end') {
            isThinking = false;
            opts.onThinkingEnd?.();
          } else if (part.type === 'text-delta') {
            if (!toolDetected) {
              appendAggregate(part.text);
              const found = extractToolUses(aggregateText);
              if (toolParsingEnabled && found.length > 0) {
                toolUses.push(...found);
                toolDetected = true;
                // ä¸€æ—¦æ£€æµ‹åˆ°å·¥å…·ï¼Œåœæ­¢å‘å¤–è¾“å‡ºæ­£æ–‡ï¼Œé¿å…æ ‡ç­¾æ³„éœ²/é‡å¤
              } else {
                opts.onToken?.(part.text);
              }
            }
          } else if (part.type === 'finish-step') {
            // usage ç»Ÿè®¡ï¼ˆå¯é€‰ï¼‰
            continue;
          } else if (part.type === 'finish') {
            if (isThinking) {
              opts.onThinkingEnd?.();
            }
            didFinish = true;
            break;
          } else if (part.type === 'error') {
            if (didFinish) {
              logger.warn('[AiClient] å¿½ç•¥ finish ä¹‹åçš„æ™šåˆ°é”™è¯¯äº‹ä»¶', { error: part.error });
              continue;
            }
            try { opts.onError?.(part.error); } catch (cbErr) {
              logger.warn('[AiClient] onError å›è°ƒæŠ›å¼‚å¸¸ï¼Œå·²å¿½ç•¥ä»¥ä¿è¯æµç»§ç»­', { error: (cbErr as any)?.message });
            }
            continue;
          }
        }
      } else {
        // æ— æ€è€ƒé“¾ï¼Œå¤„ç†çº¯æ–‡æœ¬æµ
        for await (const delta of result.textStream) {
          if (!toolDetected) {
            appendAggregate(delta);
            const found = extractToolUses(aggregateText);
            if (toolParsingEnabled && found.length > 0) {
              toolUses.push(...found);
              toolDetected = true;
            } else {
              opts.onToken?.(delta);
            }
          }
        }
      }
    } catch (e: any) {
      if (didFinish && (e?.name === 'APICallError' || /abort|cancel|closed|stream/i.test(String(e?.message || '')))) {
        logger.warn('[AiClient] finish ä¹‹åçš„æ™šåˆ°å¼‚å¸¸å·²å¿½ç•¥', { name: e?.name, message: e?.message });
        return;
      }
      logger.error('[AiClient Error]', { provider, model, error: e, message: e?.message, cause: e?.cause, stack: e?.stack });
      opts.onError?.(e);
      throw e;
    }

    // ä¸€æ®µæµç»“æŸï¼Œè‹¥å‘ç°å·¥å…·ä¸”æœªè¶…è¿‡é€’å½’æ·±åº¦ï¼Œåˆ™æ‰§è¡Œå·¥å…·å¹¶é€’å½’
    if (toolParsingEnabled && toolUses.length > 0 && depth < 3) {
      try {
        const toolResultsText = await runMcpToolsAndSummarize(toolUses, opts);
        const nextMessages = [
          ...messages,
          { role: 'user', content: toolResultsText },
        ];
        // é‡ç½®æ£€æµ‹çŠ¶æ€ï¼Œå…è®¸ç¬¬äºŒæ®µå†æ¬¡è§£æåç»­å·¥å…·ï¼ˆè‹¥æ¨¡å‹ç»§ç»­äº§ç”Ÿï¼‰
        toolUses.length = 0;
        toolDetected = false;
        await runOnePass(nextMessages, depth + 1);
        return;
      } catch (toolErr) {
        logger.error('[AiClient] æ‰§è¡Œ MCP å·¥å…·å¤±è´¥', toolErr as any);
        // å·¥å…·å¤±è´¥æ—¶ï¼Œä¸å†é€’å½’ï¼Œç»“æŸæœ¬è½®
      }
    }
  };

  await runOnePass(initialMessages, 0);
  opts.onDone?.();
  
  return;
}

/**
 * æ‰§è¡Œè§£æåˆ°çš„ MCP å·¥å…·å¹¶ç”Ÿæˆå¯ä¾›ç¬¬äºŒè½®å¯¹è¯ä½¿ç”¨çš„ç”¨æˆ·æ¶ˆæ¯æ–‡æœ¬
 */
async function runMcpToolsAndSummarize(
  toolUses: Array<{ name: string; args: any }>,
  opts: StreamOptions
): Promise<string> {
  // æ„å»º name -> { serverId, tool } ç´¢å¼•
  const activeServers = await McpServersRepository.getActiveServers();
  const nameIndex = new Map<string, { serverId: string; tool: MCPTool }>();
  for (const srv of activeServers) {
    try {
      const tools = await mcpClient.listTools(srv.id);
      for (const t of tools) {
        if (!nameIndex.has(t.name)) {
          nameIndex.set(t.name, { serverId: srv.id, tool: t });
        }
      }
    } catch (e) {
      logger.warn('[AiClient] åŠ è½½æœåŠ¡å™¨å·¥å…·å¤±è´¥ï¼Œè·³è¿‡è¯¥æœåŠ¡å™¨', { serverId: srv.id, error: (e as any)?.message });
    }
  }

  let summary = '';
  for (const use of toolUses) {
    try {
      const entry = nameIndex.get(use.name);
      if (!entry) {
        const notFound = `MCP å·¥å…·æœªæ‰¾åˆ°: ${use.name}`;
        summary += `Here is the result of mcp tool use \`${use.name}\`:\n${notFound}\n`;
        try { opts.onToolResult?.(use.name, { error: notFound }); } catch {}
        continue;
      }

      try { opts.onToolCall?.(use.name, use.args); } catch {}
      const result: MCPToolResult = await mcpClient.callTool(entry.serverId, use.name, use.args || {});
      try { opts.onToolResult?.(use.name, result); } catch {}

      const text = formatMcpResultToMessageText(use.name, result);
      summary += text + '\n';
    } catch (err: any) {
      const msg = typeof err?.message === 'string' ? err.message : String(err);
      summary += `Here is the result of mcp tool use \`${use.name}\`:\nError: ${msg}\n`;
      try { opts.onToolResult?.(use.name, { error: msg }); } catch {}
    }
  }
  return summary.trim();
}

function formatMcpResultToMessageText(toolName: string, result: MCPToolResult): string {
  if (!result) {
    return `Here is the result of mcp tool use \`${toolName}\`:\n(no content)`;
  }
  if (result.isError) {
    const errText = (result.content || [])
      .filter((c) => c.type === 'text' && typeof c.text === 'string')
      .map((c) => c.text)
      .join('\n');
    return `Here is the result of mcp tool use \`${toolName}\`:\nError: ${errText || 'unknown error'}`;
  }
  const lines: string[] = [`Here is the result of mcp tool use \`${toolName}\`:`];
  for (const item of result.content || []) {
    if (item.type === 'text' && typeof item.text === 'string') {
      lines.push(item.text);
    } else if (item.type === 'image' && item.data && item.mimeType) {
      lines.push(`image: data:${item.mimeType};base64,${item.data}`);
    } else if (item.type === 'resource' && item.uri) {
      lines.push(`resource: ${item.uri}`);
    }
  }
  if (lines.length === 1) lines.push('(no content)');
  return lines.join('\n');
}

// ============================================
// å›¾ç‰‡ç”ŸæˆåŠŸèƒ½
// ============================================

/**
 * å›¾ç‰‡ç”Ÿæˆé€‰é¡¹æ¥å£
 */
export interface GenerateImageOptions {
  provider: Provider;
  model: string;
  prompt: string;
  n?: number; // ç”Ÿæˆæ•°é‡ï¼ˆé»˜è®¤ 1ï¼‰
  size?: '1024x1024' | '1792x1024' | '1024x1792' | '256x256' | '512x512'; // å›¾ç‰‡å°ºå¯¸
  quality?: 'standard' | 'hd'; // å›¾ç‰‡è´¨é‡ï¼ˆä»… DALL-E 3ï¼‰
  style?: 'vivid' | 'natural'; // é£æ ¼ï¼ˆä»… DALL-E 3ï¼‰
  abortSignal?: AbortSignal;

  // æµå¼å›è°ƒ
  onCreated?: () => void;
  onProgress?: (progress: number) => void; // è¿›åº¦ï¼ˆ0-100ï¼‰
  onComplete?: (imageData: ImageGenerationResult) => void;
  onError?: (error: ImageGenerationError) => void;
}

/**
 * å›¾ç‰‡ç”Ÿæˆç»“æœæ¥å£
 */
export interface ImageGenerationResult {
  type: 'url' | 'base64';
  images: string[]; // URL åˆ—è¡¨æˆ– Base64 æ•°æ®ï¼ˆData URI æ ¼å¼ï¼šdata:image/png;base64,...ï¼‰
  revisedPrompt?: string; // DALL-E 3 è¿”å›çš„ä¼˜åŒ–åæç¤ºè¯ï¼ˆæ³¨ï¼šå½“å‰ Vercel AI SDK æœªæä¾›ï¼‰
}

/**
 * ç”Ÿæˆå›¾ç‰‡ï¼ˆä½¿ç”¨ Vercel AI SDK å®˜æ–¹ APIï¼‰
 *
 * @example
 * ```typescript
 * const result = await generateImageWithAI({
 *   provider: 'openai',
 *   model: 'dall-e-3',
 *   prompt: 'ä¸€åªå¯çˆ±çš„æ©˜çŒ«ååœ¨æœˆçƒä¸Š',
 *   size: '1024x1024',
 *   quality: 'hd',
 *   onCreated: () => logger.debug('å¼€å§‹ç”Ÿæˆ'),
 *   onComplete: (data) => logger.debug('ç”Ÿæˆå®Œæˆ', data),
 * });
 * ```
 */
export async function generateImageWithAI(
  options: GenerateImageOptions
): Promise<ImageGenerationResult> {
  const {
    provider,
    model,
    prompt,
    n = 1,
    size = '1024x1024',
    quality = 'standard',
    style = 'vivid',
    abortSignal,
    onCreated,
    onProgress,
    onComplete,
    onError,
  } = options;

  try {
    // 1. éªŒè¯æ¨¡å‹æ”¯æŒ
    if (!isDedicatedImageGenerationModel(model)) {
      throw new ImageModelResolutionError(model, provider);
    }

    // 2. éªŒè¯æç¤ºè¯
    if (!prompt || prompt.trim().length === 0) {
      throw new ImageGenerationError(
        'è¯·è¾“å…¥å›¾ç‰‡æè¿°æç¤ºè¯',
        provider,
        model
      );
    }

    // 3. éªŒè¯æç¤ºè¯é•¿åº¦ï¼ˆDALL-E é™åˆ¶ï¼‰
    if (prompt.length > 4000) {
      throw new ImageGenerationError(
        'æç¤ºè¯è¿‡é•¿ï¼Œè¯·æ§åˆ¶åœ¨ 4000 å­—ç¬¦ä»¥å†…',
        provider,
        model
      );
    }

    // 4. è·å– API Key
    const apiKey = await getApiKey(provider);
    if (!apiKey) {
      throw new ImageGenerationError(
        `ç¼ºå°‘ ${provider} çš„ API Keyï¼Œè¯·å…ˆåœ¨è®¾ç½®ä¸­é…ç½®`,
        provider,
        model
      );
    }

    // 5. å‘é€åˆ›å»ºäº‹ä»¶
    onCreated?.();
    onProgress?.(10);


    // 6. è·å– baseURLï¼ˆå¦‚æœæœ‰è‡ªå®šä¹‰ï¼‰
    let baseURL: string | undefined;
    if (provider === 'openai' || provider === 'deepseek' || provider === 'volc' || provider === 'zhipu') {
      const cfg = await ProvidersRepository.getConfig(provider as ProviderId);
      baseURL = cfg.baseURL || undefined;
    }

    // 7. åˆ›å»ºæä¾›å•†å®ä¾‹
    const factory = provider === 'openai'
      ? () => createOpenAI({ apiKey, baseURL })
      : provider === 'deepseek' || provider === 'volc' || provider === 'zhipu'
      ? () => createOpenAICompatible({
          apiKey,
          baseURL: baseURL ?? 'https://api.openai.com/v1',
          name: provider
        })
      : () => {
          throw new ImageGenerationError(
            `æä¾›å•† ${provider} æš‚ä¸æ”¯æŒå›¾ç‰‡ç”Ÿæˆ`,
            provider,
            model
          );
        };

    onProgress?.(30);

    // 8. è°ƒç”¨ Vercel AI SDK å®˜æ–¹ API
    const result = await generateImage({
      model: factory().imageModel(model), // ä½¿ç”¨ imageModel æ–¹æ³•
      prompt: prompt,
      n: n,
      size: size,
      ...(model.toLowerCase().includes('dall-e-3') && {
        // DALL-E 3 ä¸“å±å‚æ•°ï¼ˆé€šè¿‡ providerOptions ä¼ é€’ï¼‰
        providerOptions: {
          openai: {
            quality: quality,
            style: style,
          }
        }
      }),
      abortSignal: abortSignal,
    });

    onProgress?.(80);

    // 9. è½¬æ¢ç»“æœæ ¼å¼ï¼šGeneratedFile[] -> string[]
    const images: string[] = [];
    if (result.images) {
      for (const image of result.images) {
        if ('base64' in image && image.base64) {
          // å°† Base64 è½¬æ¢ä¸º Data URI æ ¼å¼
          const mediaType = image.mediaType || 'image/png';
          images.push(`data:${mediaType};base64,${image.base64}`);
        }
      }
    }


    // 10. å¤„ç†è¿”å›ç»“æœ
    const imageData: ImageGenerationResult = {
      type: 'base64',
      images: images,
      revisedPrompt: undefined, // å½“å‰ Vercel AI SDK æœªæä¾›æ­¤å­—æ®µ
    };

    onProgress?.(90);

    // 10. å‘é€å®Œæˆäº‹ä»¶
    onComplete?.(imageData);
    onProgress?.(100);

    return imageData;
  } catch (error: any) {
    // é”™è¯¯å¤„ç†
    logger.error('[AiClient] å›¾ç‰‡ç”Ÿæˆå¤±è´¥', {
      provider,
      model,
      error: error,
      message: error?.message,
      stack: error?.stack,
    });

    const imageError = error instanceof ImageGenerationError
      ? error
      : new ImageGenerationError(
          error.message || 'å›¾ç‰‡ç”Ÿæˆå¤±è´¥',
          provider,
          model,
          error
        );

    onError?.(imageError);
    throw imageError;
  }
}
