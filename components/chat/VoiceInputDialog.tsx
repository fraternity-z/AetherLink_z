/**
 * ğŸ¤ è¯­éŸ³è¾“å…¥å¯¹è¯æ¡†ç»„ä»¶
 *
 * åŠŸèƒ½ï¼š
 * - æ˜¾ç¤ºå½•éŸ³çŠ¶æ€å’Œæ—¶é•¿
 * - æä¾›åœæ­¢å’Œå–æ¶ˆæŒ‰é’®
 * - é›†æˆè¯­éŸ³è¯†åˆ«åŠŸèƒ½ï¼ˆè®¾å¤‡ç«¯ + Whisper APIï¼‰
 * - æ˜¾ç¤ºè¯†åˆ«è¿›åº¦å’Œé”™è¯¯æç¤º
 */

import React, { useEffect, useState } from 'react';
import { View, StyleSheet } from 'react-native';
import { Portal, Dialog, Button, Text, ActivityIndicator, useTheme } from 'react-native-paper';
import { MaterialCommunityIcons } from '@expo/vector-icons';
import { useVoiceRecording } from '@/hooks/use-voice-recording';
import { useVoiceRecognition } from '@/hooks/use-voice-recognition';
import { SettingsRepository, SettingKey } from '@/storage/repositories/settings';
import { logger } from '@/utils/logger';

interface VoiceInputDialogProps {
  visible: boolean;
  onClose: () => void;
  onTextRecognized: (text: string) => void;
  maxDuration?: number;
}

export function VoiceInputDialog({
  visible,
  onClose,
  onTextRecognized,
  maxDuration = 120,
}: VoiceInputDialogProps) {
  const theme = useTheme();
  const {
    isRecording,
    duration,
    audioUri,
    startRecording,
    stopRecording,
    cancelRecording,
    formatDuration,
  } = useVoiceRecording(maxDuration, handleMaxDurationReached);

  // è¯­éŸ³è¯†åˆ« Hook
  const {
    isRecognizing,
    error: recognitionError,
    recognizeFromFile,
    clearError,
  } = useVoiceRecognition({ autoLoadSettings: true });

  // è¯†åˆ«æä¾›å•†çŠ¶æ€
  const [provider, setProvider] = useState<'native' | 'whisper'>('native');
  const [autoSend, setAutoSend] = useState(false);

  // åŠ è½½è®¾ç½®
  useEffect(() => {
    if (visible) {
      loadSettings();
    }
  }, [visible]);

  // åŠ è½½è¯­éŸ³è®¾ç½®
  const loadSettings = async () => {
    try {
      const sr = SettingsRepository();
      const savedProvider = (await sr.get<'native' | 'whisper'>(SettingKey.VoiceProvider)) || 'native';
      const savedAutoSend = (await sr.get<boolean>(SettingKey.VoiceAutoSend)) || false;

      setProvider(savedProvider);
      setAutoSend(savedAutoSend);

      logger.debug('[VoiceInputDialog] Settings loaded:', {
        provider: savedProvider,
        autoSend: savedAutoSend,
      });
    } catch (error) {
      logger.error('[VoiceInputDialog] Failed to load settings:', error);
    }
  };

  // å¯¹è¯æ¡†æ‰“å¼€æ—¶è‡ªåŠ¨å¼€å§‹å½•éŸ³
  useEffect(() => {
    if (visible) {
      logger.debug('[VoiceInputDialog] Dialog opened, starting recording');
      startRecording().catch((error) => {
        logger.error('[VoiceInputDialog] Failed to start recording:', error);
        onClose();
      });
    }

    // å¯¹è¯æ¡†å…³é—­æ—¶ç¡®ä¿å½•éŸ³å·²åœæ­¢
    return () => {
      if (isRecording) {
        cancelRecording();
      }
    };
  }, [visible]);

  // è¾¾åˆ°æœ€å¤§æ—¶é•¿æ—¶çš„å¤„ç†
  function handleMaxDurationReached() {
    logger.debug('[VoiceInputDialog] Max duration reached');
    handleStop();
  }

  // åœæ­¢å½•éŸ³å¹¶è¿›è¡Œè¯­éŸ³è¯†åˆ«
  const handleStop = async () => {
    try {
      const uri = await stopRecording();
      if (!uri) {
        logger.warn('[VoiceInputDialog] No audio URI, cannot proceed');
        onClose();
        return;
      }

      logger.debug('[VoiceInputDialog] Recording stopped, URI:', uri);

      // ä½¿ç”¨ Whisper API è¯†åˆ«ï¼ˆä»éŸ³é¢‘æ–‡ä»¶ï¼‰
      if (provider === 'whisper') {
        try {
          logger.debug('[VoiceInputDialog] Starting Whisper recognition');
          const text = await recognizeFromFile(uri);

          if (text && text.trim()) {
            logger.debug('[VoiceInputDialog] Recognition successful:', text);
            onTextRecognized(text);
          } else {
            logger.warn('[VoiceInputDialog] Recognition returned empty text');
          }

          onClose();
        } catch (error: any) {
          logger.error('[VoiceInputDialog] Recognition failed:', error);
          // é”™è¯¯ä¼šæ˜¾ç¤ºåœ¨å¯¹è¯æ¡†ä¸­ï¼Œä¸ç›´æ¥å…³é—­
        }
      } else {
        // è®¾å¤‡ç«¯è¯†åˆ«ä¸æ”¯æŒä»æ–‡ä»¶è¯†åˆ«ï¼Œæ˜¾ç¤ºæç¤º
        logger.warn('[VoiceInputDialog] Native recognition does not support file recognition');
        onTextRecognized('[è®¾å¤‡ç«¯è¯†åˆ«ä»…æ”¯æŒå®æ—¶è¯†åˆ«ï¼Œè¯·åœ¨è¯­éŸ³è®¾ç½®ä¸­åˆ‡æ¢åˆ° Whisper API]');
        onClose();
      }
    } catch (error) {
      logger.error('[VoiceInputDialog] Stop recording failed:', error);
      onClose();
    }
  };

  // å–æ¶ˆå½•éŸ³
  const handleCancel = async () => {
    await cancelRecording();
    onClose();
  };

  return (
    <Portal>
      <Dialog visible={visible} onDismiss={handleCancel} style={styles.dialog}>
        <Dialog.Title style={styles.title}>
          {isRecognizing ? 'è¯†åˆ«ä¸­...' : isRecording ? 'å½•éŸ³ä¸­...' : 'è¯­éŸ³è¾“å…¥'}
        </Dialog.Title>
        <Dialog.Content>
          {/* éº¦å…‹é£å›¾æ ‡ */}
          <View style={styles.iconContainer}>
            {isRecognizing ? (
              <ActivityIndicator size={64} color={theme.colors.primary} />
            ) : (
              <MaterialCommunityIcons
                name="microphone"
                size={64}
                color={isRecording ? theme.colors.error : theme.colors.primary}
              />
            )}
          </View>

          {/* å½•éŸ³æ—¶é•¿æ˜¾ç¤º */}
          {isRecording && (
            <Text variant="headlineMedium" style={styles.timer}>
              {formatDuration(duration)} / {formatDuration(maxDuration)}
            </Text>
          )}

          {/* æç¤ºæ–‡æœ¬ */}
          {isRecording && !isRecognizing && (
            <Text variant="bodyMedium" style={styles.hint}>
              æ­£åœ¨å½•éŸ³ï¼Œç‚¹å‡»åœæ­¢æŒ‰é’®å®Œæˆå½•éŸ³
            </Text>
          )}

          {/* è¯†åˆ«ä¸­æç¤º */}
          {isRecognizing && (
            <Text variant="bodyMedium" style={styles.hint}>
              {provider === 'whisper' ? 'æ­£åœ¨ä½¿ç”¨ Whisper API è¯†åˆ«...' : 'æ­£åœ¨è¯†åˆ«...'}
            </Text>
          )}

          {/* é”™è¯¯æç¤º */}
          {recognitionError && (
            <View style={styles.errorContainer}>
              <MaterialCommunityIcons
                name="alert-circle"
                size={24}
                color={theme.colors.error}
              />
              <Text variant="bodyMedium" style={[styles.errorText, { color: theme.colors.error }]}>
                {recognitionError.getUserMessage()}
              </Text>
            </View>
          )}
        </Dialog.Content>

        <Dialog.Actions>
          <Button
            onPress={handleCancel}
            mode="text"
            disabled={isRecognizing}
          >
            å–æ¶ˆ
          </Button>
          <Button
            onPress={handleStop}
            mode="contained"
            disabled={!isRecording || isRecognizing}
            loading={isRecognizing}
          >
            {isRecognizing ? 'è¯†åˆ«ä¸­' : 'åœæ­¢å½•éŸ³'}
          </Button>
        </Dialog.Actions>
      </Dialog>
    </Portal>
  );
}

const styles = StyleSheet.create({
  dialog: {
    borderRadius: 16,
  },
  title: {
    textAlign: 'center',
  },
  iconContainer: {
    alignItems: 'center',
    marginVertical: 24,
  },
  timer: {
    textAlign: 'center',
    fontWeight: '600',
    marginBottom: 16,
  },
  hint: {
    textAlign: 'center',
    opacity: 0.7,
  },
  errorContainer: {
    flexDirection: 'row',
    alignItems: 'center',
    justifyContent: 'center',
    marginTop: 16,
    paddingHorizontal: 16,
  },
  errorText: {
    marginLeft: 8,
    flex: 1,
    textAlign: 'center',
  },
});
